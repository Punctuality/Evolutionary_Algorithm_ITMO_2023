# Лабораторная работа №1

**Дисциплина:** "Эволюционные вычисления"

**Дата:** 15/02/2023

**Выполнил:** Федоров Сергей, M4150 

**Название:** "Сложность алгоритмов и их оптимизация"

**Вариант:**

| *№* | Алгоритм |
|------| ------- |
| 22 | Сжатие кода Хаффмана |

## Описания выполнения:

Было принято решение выполнять работу в формате следующих шагов:

1. Реализоваться утилиту тестирования по времени и эффективности алгоритма сжатия
2. Реализовать утилиту генерации тестовых данных
3. Реализовать базовый вариант алгоритма на Python (условно стандартная реализация кода Хаффмана)
4. Попытаться реализовать оптимизации алгоритма
5. Реализовать на оптимизированный вариант алгоритма на системном языке (оптимизация за счет ЯП). В моем случае я выбираю Rust.
6. Тестирование всех решений по мере их реализации и сравнение результатов в конце

### Описания программы на Python

Реализованная программа разделена на следующие файлы, которые содержат свою соответствующую функциональность:
1. `graph.py` - Содержит реализацию класса `BinaryNode`, имеющий поля `left`, `right`, `value`, `weight`, дополнительные методы и переопределенные операторы сравнения.
2. `huffman_naive.py` - Содержит реализацию алгоритма построения H-дерева и кодирования строки. Данный вариант алгоримта - является условно "стандартным" и не содержить специфических оптимизаций. Тем не менее, в предоставленном исходном кода - содержутся комментарии к возможным оптимизациям.
3. `huffman_optimized.py` - Содержит схожую с `huffman_naive.py` функциональность. Данный вариант алгоримта - является оптимизированным вариантом алгоритма, который содержит следующие оптимизации (некоторые были убраны, за отсутстием результата):
  
    a. Используем более эффективный метод сортировки Counter'a (вместо `sorted` используем `heapq.nlargest`)

    b. Использовались битовые строки для работы с кодами символов (прироста по скорости - не дало)

    c. Оптимизация DFS (использование списка вместо рекурсии). Прироста по скорости - не дает, ибо глубина дерева - мала (число уникальных символов для StackOverFlow должно быть больше 2^256), а изменение коллекции не быстрее чем вызов метода.

    d. Основной прирост в скорости - при построении дерева, каждый раз после добавления нового узла, нет необходимости сортировать весь список. Достаточно использовать бинарный поиск для поиска места вставки нового узла.

4. `perf_test.py` - Содержит реализацию утилиты для тестирования алгоритма по времени и эффективности. Данная утилита позволяет тестировать алгоритмы на различных входных данных и с различным количеством итераций. Результаты тестирования выводяться в `stdout`

### Выводы по оптимизациям на Python

Проделанные оптимизации, как и были должны - не улучшали эффективность сжатия данных. Однако, был получен некоторый прирост в скорости работы алгоритма. Прирост в скорости в среднем составил ~5%, хотя в некоторых случаях погрешность измерений перекрывала это улучшение. 

Как видно, сильно с оптимизировать алгоритм без изменения его сути - не получается. И основные затраты по времени уходят на момент подсчета частотности символов и составления итогого ответа (конкатенация строк). Данные момент можно оптимизировать используя болле "производительный" ЯП с некоторой низкоуровневой оптимизацией. В моем случае - это Rust.

Стоит заметить что можно использовать модификации алгоритма Хаффмана (например Адаптивное построение дерева), но в данном случае их использование не приведет к увелечению производительности.

[Вывод программы `python3 main.py`](https://github.com/Punctuality/Evolutionary_Algorithm_ITMO_2023/blob/main/Lab_1/python_lab_1/README.md)

### Описания программы на Rust

Реализованная программа разделена на следующие файлы, которые содержат свой соответствующий функционал:
1. `Cargo.toml` - файл конфигурации проекта, для сборки и запуска.
2. `binary_node.rs` - Повторяет функциональность `graph.py` и содержит описание структуры `BinaryNode`, имеющей поля `left`, `right`, `value`, `weight`, дополнительные методы и переопределенные операторы сравнения и отображения. Стоит отметить что `BinaryNode` - рекурсивная структура, которые сложно реализовывать на Rust из-за его системы типов. Поэтому из возможных реализаций был выбран `Arena Allocator` (другие подходы: `raw pointers`, `Rc<RefCell<&Node>>`), потому как позволяет создавать пулл-объектов с одинаковым lifetime и задачи удаления вершин графа перед нами не стоит.
3. `math_util.rs` - Содержит реализацию функций `mean`, `std` и `round_digits`.
4. `huffman.rs` - Повторяет функциональность `huffman_optimized.py` и содержит специфические для Rust оптимизации, такие как:

    a. Вышеупомянутый `Typed Arena Allocator` для создания пулла вершин графа.

    b. Использования итераторов для всех операций с коллекциями.

    c. Переопределение хэш-функции для таблицы подсчета частотности символов и кодов символов. Используется `NoHashHasher`, который подставляет используемый ключ сразу же как хэш, что в нашем случае возможно потому как мы рассматриваем тип символа `char` как `u32` (беззнаковый 32-битный целый тип). Только данная оптимизация сразу же дает прирост в скорости в два раза.

5. `perf_test.rs` - Повторяет функциональность `perf_test.py`

[Вывод программы `cargo run --release`](https://github.com/Punctuality/Evolutionary_Algorithm_ITMO_2023/blob/main/Lab_1/rust_lab_1/README.md)

### Выводы по оптимизациям на Rust

Замеры производительности производились во время всего процесса разработки и только при смене ЯП, данная оптимизация давала прирост в 2-3 раза по сравнению с аналогом на Python. После проведенных оптимизаций спецефичных для Rust, прирост в скорости в среднем составляет ~6.5 раз (мне даже пришлось улучшать отображение в `perf_test.rs` для того чтобы измерять и милли- и микро- секунды).

### Оценка сложности алгоритма

Алгоритм кодирования Хаффмана, в конкретной реализации разбита на 4 шага:
1. Подсчет частотности символов во входной строке - **O(n + k * log(k))**
2. Построение дерева Хаффмана - C оптимизациями: **O(k * log(k))**, без оптимизаций: **O(k^2 * log(k)))**
3. Построение таблицы кодов символов - **O(V + E)** -> **O((k + log(k)) + (k + log(k) - 1))** -> **O(k + log(k))**
4. Кодирование входной строки - **O(n)**

* **n** - размер входной строки
* **k** - количество уникальных символов во входной строке

**Итоговая сложность алгоритма** - **O(n + k * log(k))**

### Результаты замера производительности

Ниже предоставлены замеры по времени и эффективности сжатия в зависимости от предоставленных данных и ЯП. Стоит заметить что все тесты были проведены не один раз, что позволяет увидеть некоторую погрешность в результатах.

| **Алгоритм** | **Размер входной строки** | **Максимальное кол-во последовательных символов** | **Кол-во тестов** | **Время выполнения** | **Эффективность сжатия** |
|---|---|---|---|---|---|
| 🐍 Python naive | 1000 | 5 | 1000 | 0.179 ms ± 0.046 ms | 0.417 % |
| 🐍 Python optimized | 1000 | 5 | 1000 | 0.161 ms ± 0.036 ms | 0.417 % |
| 🦀 Rust | 1000 | 5 | 1000 | 35.935 μs ± 0.317 μs | 0.417 % |
| 🐍 Python naive | 1e+7 | 1000 | 10 | 825.5 ms ± 17.288 ms | 0.405 % |
| 🐍 Python optimized | 1e+7 | 1000 | 10 | 839.834 ms ± 13.312 ms | 0.405 % |
| 🦀 Rust | 1e+7 | 1000 | 10 | 131 ms ± 5.042 ms | 0.405 % |
| 🐍 Python naive | 1e+8 | 1000 | 3 | 8524.109 ms ± 44.272 ms | 0.404 % |
| 🐍 Python optimized | 1e+8 | 1000 | 3 | 8485.963 ms ± 100.24 ms | 0.404 % |
| 🦀 Rust | 1e+8 | 1000 | 3 | 1299.667 ms ± 44.784 ms | 0.404 % |

## Выводы

В ходе выполнения лабораторной работы был изучен (освежен в памяти) принцип работ алгоритма Хаффмана, а также были реализованы версии на Python и Rust, с оптимизациями и без. Были проведены замеры производительности и сравнены результаты, составлена итоговая таблица. Оптимизации на Rust, позволили увеличить скорость работы алгоритма в ~6.5 раз, по сравнению со "стандартной" реализацией на Python. Была проведена оценка сложности алгоритма.
